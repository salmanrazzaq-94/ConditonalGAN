{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CGAN_trainer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNe4C0LEmqhocRPEyvJJAr/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"C67bQ74f9ZE8","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from numpy import load\n","from numpy import zeros\n","from numpy import ones\n","from numpy import asarray\n","from numpy import append\n","from numpy.random import random\n","from numpy.random import randint\n","from numpy.random import shuffle\n","import time\n","import os\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adamax\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Reshape\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Conv2DTranspose\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.layers import Concatenate\n","from keras.models import load_model\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.utils import plot_model\n","from matplotlib import patheffects as path_effects\n","import collections\n","from tensorflow.keras.models import load_model\n","from tensorflow import get_logger as log\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QzwHFOqUKG0F","colab_type":"code","colab":{}},"source":["!pip install -q pydot\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2TRZpeE9rNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5616493e-8c9c-41cc-9678-8c50716fd346","executionInfo":{"status":"ok","timestamp":1588256492520,"user_tz":-120,"elapsed":4724,"user":{"displayName":"Salman Razzaq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxMmug64Lz6tRF9sfFXUNNN3mSkMxSbzm2i2urJg=s64","userId":"18330507046486039566"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ieJBJTqG-gpj","colab_type":"code","outputId":"22d4e4a2-7953-422f-852b-5d6b4ffa9a33","executionInfo":{"status":"ok","timestamp":1588256494810,"user_tz":-120,"elapsed":6984,"user":{"displayName":"Salman Razzaq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxMmug64Lz6tRF9sfFXUNNN3mSkMxSbzm2i2urJg=s64","userId":"18330507046486039566"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["os.chdir(\"/content/drive/My Drive/deeplearning/\")\n","!ls"],"execution_count":10,"outputs":[{"output_type":"stream","text":["cgan\t\t\t\t      img_align_celeba_attractive_full.npz\n","gan_model.png\t\t\t      latent_points_10000.npz\n","generated_faces_200.png\t\t      latent_points_100.npz\n","ids_align_celeba_attractive_face.npz  latent_points_200.npz\n","ids_align_celeba_attractive_full.npz  list_attr_celeba.csv\n","img_align_celeba_attractive_face.npz  results\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sCHO27dL-gsS","colab_type":"code","colab":{}},"source":["#  SET YOUR FLAGS\n","qErrorHide = False\n","if qErrorHide:\n","    print(\"\\n***REMEMBER:  WARNINGS turned OFF***\\n***REMEMBER:  WARNINGS turned OFF***\\n\")\n","    log().setLevel('ERROR')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DAtJ0X_-gvD","colab_type":"code","colab":{}},"source":["#    INDICATE IF STARTING FRESH OR CONTINUING FROM PREVIOUS RUN\n","qRestart = False\n","if qRestart:\n","    epochs_done = 85\n","    epochs_goal = 200\n","else:\n","    epochs_done = 0\n","    epochs_goal = 100 \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJEpq7ZT-g1b","colab_type":"code","colab":{}},"source":["# define the standalone discriminator model\n","def define_discriminator(in_shape=(80,80,3), n_classes=4):\n","    print(\"**********  ENTERED discriminator  *****************\")\n","    ##### foundation for labels\n","    in_label = Input(shape=(1,))\n","    embedding_layer = Embedding(n_classes, 8)\n","    # embedding_layer.trainable = False\n","    li = embedding_layer (in_label)\n","    n_nodes = in_shape[0] * in_shape[1]\n","    print(\">>embedding>> in_shape[0], in_shape[1], n_nodes: \", in_shape[0], in_shape[1], n_nodes)\n","    li = Dense(n_nodes)(li)\n","    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n","    # image input\n","    dropout = 0.1\n","    in_image = Input(shape=in_shape)\n","    print(\"\\nin_image: \", in_image)\n","    # concat label as a channel\n","    merge = Concatenate()([in_image, li])\n","    print(\"\\nmerge.shape: \", merge.shape)\n","    # sample to 80x80\n","    fe = Conv2D(128, (5,5), padding='same')(merge)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Dropout(dropout)(fe)\n","    print(\"fe.shape: \", fe.shape)\n","    # downsample to 40x40\n","    fe = Conv2D(128, (5,5), strides=(2,2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    # fe = Dropout(dropout)(fe)\n","    print(\"fe.shape: \", fe.shape)\n","    # downsample to 20x20\n","    fe = Conv2D(128, (5,5), strides=(2,2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    # fe = Dropout(dropout)(fe)\n","    print(\"fe.shape: \", fe.shape)\n","    # downsample to 10x10\n","    fe = Conv2D(128, (5,5), strides=(2,2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    # fe = Dropout(dropout)(fe)\n","    print(\"fe.shape: \", fe.shape)\n","    # downsample to 5x5\n","    fe = Conv2D(128, (5,5), strides=(2,2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    # fe = Dropout(dropout)(fe)\n","    print(\"fe.shape: \", fe.shape)\n","    # flatten feature maps\n","    fe = Flatten()(fe)\n","    # fe = Dropout(dropout)(fe)\n","    print(\"fe flatten shape: \", fe.shape)\n","    # output\n","    out_layer = Dense(1, activation='sigmoid')(fe)\n","    print(\"out_layer.shape: \", out_layer.shape)\n","    # define model\n","    model = Model([in_image, in_label], out_layer)\n","    print(\"\\nmodel: \", model)\n","    # compile model\n","    opt = Adamax(lr=0.00007, beta_1=0.08, beta_2=0.999, epsilon=10e-8)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    print(\"\\nembedding_layer.get_weights(): \\n\",embedding_layer.get_weights())\n","    model.summary()\n","    plot_model(model, to_file='cgan/discriminator_model.png')\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxbzjYhKFG4K","colab_type":"code","colab":{}},"source":["# define the standalone generator model\n","def define_generator(latent_dim, n_classes=4):\n","    print(\"**********  ENTERED generator  *****************\")\n","    ##### foundation for labels\n","    in_label = Input(shape=(1,))\n","    embedding_layer = Embedding(n_classes, 8)\n","    embedding_layer.trainable = True\n","    li = embedding_layer (in_label)\n","    n_nodes = 5 * 5\n","    li = Dense(n_nodes)(li)\n","    li = Reshape((5 , 5, 1))(li)\n","    print(\"generator...  n_nodes, li.shape: \", n_nodes, li.shape)\n","    ##### foundation for 5x5 image\n","    in_lat = Input(shape=(latent_dim,))\n","    n_nodes = 128 * 5 * 5\n","    genX = Dense(n_nodes)(in_lat)\n","    genX = LeakyReLU(alpha=0.2)(genX)\n","    genX = Reshape((5, 5, 128))(genX)\n","    dropout = 0.1\n","    print(\"genX.shape: \", genX.shape)\n","    ##### merge image gen and label input\n","    merge = Concatenate()([genX, li])\n","    print(\"merge.shape: \", merge.shape)\n","    ##### create merged model\n","    # upsample to 10x10\n","    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n","    print(\"gen after CV2DT.shape: \", gen.shape)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    gen = Dropout(dropout)(gen)\n","    print(\"gen.shape: \", gen.shape)\n","    # upsample to 20x20\n","    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    print(\"gen.shape: \", gen.shape)\n","    # upsample to 40x40\n","    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    print(\"gen.shape: \", gen.shape)\n","    # upsample to 80x80\n","    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    print(\"gen.shape: \", gen.shape)\n","    # output layer 80x80x3\n","    out_layer = Conv2D(3, (5,5), activation='tanh', padding='same')(gen)\n","    print(\"out_layer.shape: \", out_layer.shape)\n","    # define model\n","    model = Model(inputs=[in_lat, in_label], outputs=out_layer)\n","    opt = Adamax(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n","    model.compile(loss=['binary_crossentropy'], optimizer=opt)\n","    print(\"\\nembedding_layer.get_weights(): \\n\",embedding_layer.get_weights())\n","    model.summary()\n","    #plot_model(model, to_file='generator_model.png')\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsX56b2c-g4J","colab_type":"code","colab":{}},"source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model):\n","    print(\"**********  ENTERED gan  *****************\")\n","    # make weights in the discriminator not trainable\n","    d_model.trainable = False\n","    # get noise and label inputs from generator model\n","    gen_noise, gen_label = g_model.input\n","    # get image output from the generator model\n","    gen_output = g_model.output\n","    # connect image output and label input from generator as inputs to discriminator\n","    gan_output = d_model([gen_output, gen_label])\n","    # define gan model as taking noise and label and outputting a classification\n","    model = Model([gen_noise, gen_label], gan_output)\n","    # compile model\n","    opt = Adamax(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n","    model.compile(loss='binary_crossentropy', optimizer=opt)\n","    model.summary()\n","    plot_model(model, to_file='gan_model.png')\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDHR6Frs-g69","colab_type":"code","colab":{}},"source":["# assign categories\n","def assign_categs(df, lenrows):\n","    print(\"\\n*****  ATTRIBUTES: \\n\", df.mean())\n","\n","    face_male = df['Male']\n","    print(\"face_male: \", face_male.mean())\n","    face_male = np.where(face_male > 0, 1, face_male)\n","    print(\"face_male: \", face_male.mean())\n","\n","    face_high_cheekbones = df['High_Cheekbones']\n","    print(\"face_high_cheekbones: \", face_high_cheekbones.mean())\n","    face_high_cheekbones = np.where(face_high_cheekbones > 0, 1, face_high_cheekbones)\n","    print(\"face_high_cheekbones: \", face_high_cheekbones.mean())\n","\n","    face_big_lips = df['Big_Lips']\n","    print(\"face_big_lips: \", face_big_lips.mean())\n","    face_big_lips = np.where(face_big_lips > 0, 1, face_big_lips)\n","    print(\"face_big_lips: \", face_big_lips.mean())\n","\n","    # replace vectors with category value\n","    categs = np.zeros(lenrows, dtype=int)\n","    print(\"categ.mean()): \", categs.mean())\n","    categs = np.where(face_male > 0, 1, categs)\n","    print(\"add face_male: categs.mean()): \", categs.mean())\n","    categs = np.where((face_high_cheekbones > 0)&(categs==0), 2, categs)\n","    print(\"add high_cheekbones: categs.mean()): \", categs.mean())\n","    categs = np.where((face_big_lips > 0)&(categs==0), 3, categs)\n","    print(\"add big lips: categs.mean()): \", categs.mean())\n","    print(\"\\ncategs: \\n\", categs)\n","    return categs\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"850vg52a-g9z","colab_type":"code","colab":{}},"source":["def get_cumProbs(freqCategs, categs):\n","    freqLists = [freqCategs[i][1] for i in range(len(freqCategs))]\n","    freqListX = asarray(freqLists, dtype=np.float32)\n","    print(\"freqListX: \", freqListX)\n","    print(\"len(categs): \", len(categs))\n","    cumProbs = freqListX/len(categs)\n","    print(\"cumProbs: \", cumProbs)\n","    cumProbs = append((0.0),cumProbs)\n","    for i in range(len(cumProbs)-1):\n","        cumProbs[i+1]=cumProbs[i]+cumProbs[i+1]\n","    print(\"cumProbs: \", cumProbs)\n","    return cumProbs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OFMcrxU1-hAh","colab_type":"code","colab":{}},"source":["def load_real_samples():\n","    # load the face dataset\n","    data = load('img_align_celeba_attractive_face.npz')\n","    X = data['arr_0']\n","    # convert from unsigned ints to floats\n","    X = X.astype('float32')\n","    # scale from [0,255] to [-1,1]\n","    X = (X - 127.5) / 127.5\n","    data = pd.read_csv('list_attr_celeba.csv', nrows=100000)\n","    data = data.drop(\"image_id\",axis=1)\n","    ids  = load('ids_align_celeba_attractive_face.npz')\n","    idsX = ids['arr_0']\n","    dataX = list()\n","    for i,id in enumerate(idsX):\n","        dataVal = data[id:id+1].values\n","        dataVal = np.where(dataVal==-1, 0, dataVal)\n","        dataX.append(dataVal)\n","    cols = data.columns\n","    lencols = len(cols)\n","    print(\"cols: \", cols)\n","    lenrows = len(dataX)\n","    dataVals = asarray(dataX[0:]).reshape((lenrows,lencols),)\n","    df = pd.DataFrame(data=dataVals,columns=cols)\n","    pd.options.display.float_format = '{:,.3f}'.format\n","    categs = assign_categs(df, lenrows)\n","    freqCategs = list(collections.Counter(sorted(categs)).items())\n","    print(\"freqCategs: \", freqCategs)\n","    cumProbs = get_cumProbs(freqCategs, categs)\n","    return [X, categs], cumProbs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVYsukSi-hDT","colab_type":"code","colab":{}},"source":["# select real samples\n","def generate_real_samples(dataset, n_samples):\n","    # split into images and labels\n","    images, labels = dataset\n","    # choose random instances\n","    ix = randint(0, images.shape[0], n_samples)\n","    # retrieve selected images\n","    X, labels = images[ix], labels[ix]\n","    # generate 'real' class labels (1)\n","    y = ones((n_samples, 1))\n","    return [X, labels], y\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgVy1jX_-hGR","colab_type":"code","colab":{}},"source":["# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples, cumProbs, n_classes=4):\n","    # print(\"generate_latent_points: \", latent_dim, n_samples)\n","    initX = -3.0\n","    rangeX = 2.0*abs(initX)\n","    stepX = rangeX / (latent_dim * n_samples)\n","    x_input = asarray([initX + stepX*(float(i)) for i in range(0,latent_dim * n_samples)])\n","    shuffle(x_input)\n","    # generate points in the latent space\n","    z_input = x_input.reshape(n_samples, latent_dim)\n","    randx = random(n_samples)\n","    labels = np.zeros(n_samples, dtype=int)\n","    for i in range(n_classes):\n","        labels = np.where((randx >= cumProbs[i]) & (randx < cumProbs[i+1]), i, labels)\n","    return [z_input, labels]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NeVSllo-hJB","colab_type":"code","colab":{}},"source":["# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(generator, latent_dim, n_samples, cumProbs):\n","    # generate points in latent space\n","    z_input, labels_input = generate_latent_points(latent_dim, n_samples, cumProbs)\n","    # predict outputs\n","    images = generator.predict([z_input, labels_input])\n","    # create class labels\n","    y = zeros((n_samples, 1))\n","    return [images, labels_input], y\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fcbc1iUxCmjw","colab_type":"code","colab":{}},"source":["# create and save a plot of generated images\n","def save_plot(examples, labels, epoch, n=10):\n","    # scale from [-1,1] to [0,1]\n","    examples = (examples + 1) / 2.0\n","    # plot images\n","    for i in range(n * n):\n","        # define subplot\n","        fig = plt.subplot(n, n, 1 + i)\n","        strLabel = str(labels[i])\n","        # turn off axis\n","        fig.axis('off')\n","        fig.text(8.0,20.0,strLabel, fontsize=6, color='white')\n","        # plot raw pixel data\n","        fig.imshow(examples[i])\n","    # save plot to file\n","    filename = 'results/generated_plot_e%03d.png' % (epoch+1)\n","    plt.savefig(filename)\n","    plt.close()\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8HIcVecCmmf","colab_type":"code","colab":{}},"source":["def save_real_plots(dataset, nRealPlots = 5, n=10, n_samples=100):\n","    # plot images\n","    for epoch in range(nRealPlots):\n","        if epoch%5==0:\n","            print(\"real_plots: \", epoch)\n","        # prepare real samples\n","        [X_real, labels], y_real = generate_real_samples(dataset, n_samples)\n","        # scale from [-1,1] to [0,1]\n","        X_real = (X_real + 1) / 2.0\n","        for i in range(n * n):\n","            # define subplot\n","            fig = plt.subplot(n, n, 1 + i)\n","            strLabel = str(labels[i])\n","            # fig.title = strLabel\n","            # turn off axis\n","            fig.axis('off')\n","            fig.text(8.0,20.0,strLabel, fontsize=6, color='white')\n","            # plot raw pixel data\n","            fig.imshow(X_real[i])\n","        # save plot to file\n","        filename = 'results/real_plots/real_plot_e%03d.png' % (epoch+1)\n","        plt.savefig(filename)\n","        plt.close()\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"75oyYGcMCmpd","colab_type":"code","colab":{}},"source":["# evaluate the discriminator, plot generated images, save generator model\n","def summarize_performance(epoch, g_model, d_model, gan_model, dataset, latent_dim, n_samples=100):\n","    # prepare real samples\n","    [X_real, labels_real], y_real = generate_real_samples(dataset, n_samples)\n","    # evaluate discriminator on real examples\n","    _, acc_real = d_model.evaluate([X_real, labels_real], y_real, verbose=0)\n","    # prepare fake examples\n","    [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, n_samples, cumProbs)\n","    # evaluate discriminator on fake examples\n","    _, acc_fake = d_model.evaluate([X_fake, labels], y_fake, verbose=0)\n","    # summarize discriminator performance\n","    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","    # save plot\n","    save_plot(X_fake, labels, epoch)\n","    # save the generator model tile file\n","    filename = 'results/generator_model_%03d.h5' % (epoch+1)\n","    g_model.save(filename)\n","    filename = 'results/generator_model_gan%03d.h5' % (epoch+1)\n","    gan_model.save(filename)\n","    filename = 'results/generator_model_dis%03d.h5' % (epoch+1)\n","    d_model.trainable = True\n","    for layer in d_model.layers:\n","        layer.trainable = True\n","    d_model.save(filename)\n","    d_model.trainable = False\n","    for layer in d_model.layers:\n","        layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBGEsNuhCmsT","colab_type":"code","colab":{}},"source":["def restart(epochs_done):\n","    # gen_weights = array(model.get_weights())\n","    print(\"****  PULLING IN EPOCH: \", epochs_done)\n","    filename = 'results/generator_model_dis%03d.h5' % (epochs_done)\n","    d_model = load_model(filename, compile=True)\n","    d_model.trainable = True\n","    for layer in d_model.layers:\n","        layer.trainable = True\n","    d_model.summary()\n","    filename = 'results/generator_model_%03d.h5' % (epochs_done)\n","    g_model = load_model(filename, compile=True)\n","    g_model.summary()\n","    gan_model = define_gan(g_model, d_model)\n","    gan_model.summary()\n","    return d_model, g_model, gan_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgcZSpAID2bt","colab_type":"code","colab":{}},"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, latent_dim, epochs_goal=100, n_batch=128, epochs_done=1):\n","    nTryAgains = 0\n","    nTripsOnSameSavedWts = 0\n","    nSaves = 0\n","    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    d_trainable_weights = np.array(d_model.get_weights())\n","    g_trainable_weights = np.array(g_model.get_weights())\n","    gan_trainable_weights = np.array(gan_model.get_weights())\n","    now = time.time()\n","    ij = 0\n","    ijSave = -100\n","    # manually enumerate epochs\n","    for i in range(epochs_done, epochs_goal):\n","        # enumerate batches over the training set\n","        for j in range(bat_per_epo):\n","            ij+=1\n","            # get randomly selected 'real' samples\n","            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n","            qDebug=False\n","            # update discriminator model weights\n","            dis_loss, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n","            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch, cumProbs)\n","            gen_loss, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n","            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch, cumProbs)\n","            # create inverted labels for the fake samples\n","            y_gan = ones((n_batch, 1))\n","            # update the generator via the discriminator's error\n","            gan_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n","            # summarize loss on this batch\n","            if (j+1) % 5==0 or dis_loss > 1.10 or gen_loss > 1.10 or gan_loss > 1.80:\n","                diff = int(time.time()-now)\n","                print('>%d/%d, %d/%d, d1=%.3f, d2=%.3f, g=%.3f, secs=%d, tryAgain=%d, nTripsOnSameSavedWts=%d, nSaves=%d' %\n","                    (i+1, epochs_goal, j+1, bat_per_epo, dis_loss, gen_loss, gan_loss, diff, nTryAgains, nTripsOnSameSavedWts, nSaves))\n","            if dis_loss > 0.30 and dis_loss < 0.95 and gen_loss > 0.25 and gen_loss < 0.95 and gan_loss > 0.40 and gan_loss < 1.50:\n","                nTripsOnSameSavedWts = 0\n","                if ij - ijSave > 8:\n","                    nSaves+=1\n","                    ijSave = ij\n","                    d_trainable_weights = np.array(d_model.get_weights())\n","                    g_trainable_weights = np.array(g_model.get_weights())\n","                    gan_trainable_weights = np.array(gan_model.get_weights())\n","            if (dis_loss < 0.001 or dis_loss > 2.0) and ijSave > 0:\n","                nTryAgains+=1\n","                nTripsOnSameSavedWts+=1\n","                print(\"LOADING d_model\",j+1,\" from \",ijSave)\n","                d_model.set_weights(d_trainable_weights)\n","            if (gen_loss < 0.001 or gen_loss > 2.0) and ijSave > 0:\n","                nTryAgains+=1\n","                nTripsOnSameSavedWts+=1\n","                print(\"LOADING g_model\",j+1,\" from \",ijSave)\n","                g_model.set_weights(g_trainable_weights)\n","            if (gan_loss < 0.010 or gan_loss > 4.50) and ijSave > 0:\n","                nTryAgains+=1\n","                nTripsOnSameSavedWts+=1\n","                print(\"LOADING gan_models\",j+1,\" from \",ijSave)\n","                gan_model.set_weights(gan_trainable_weights)\n","            # if (j+1) % 10 == 0:\n","                # summarize_performance(i, g_model, d_model, dataset, latent_dim)\n","            if nTripsOnSameSavedWts > 20:\n","                print(\"**********  Too many rebuilds  **************\")\n","                summarize_performance(i, g_model, d_model, dataset, latent_dim)\n","                import sys\n","                sys.exit(0)\n","        # evaluate the model performance, sometimes\n","        if (i+1) % 1 == 0:\n","            summarize_performance(i, g_model, d_model, gan_model, dataset, latent_dim)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yi8_8hCMCmvB","colab_type":"code","outputId":"e70fa39b-aa64-41f8-b5ff-4f6fd6335cf1","executionInfo":{"status":"ok","timestamp":1588256527745,"user_tz":-120,"elapsed":39741,"user":{"displayName":"Salman Razzaq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxMmug64Lz6tRF9sfFXUNNN3mSkMxSbzm2i2urJg=s64","userId":"18330507046486039566"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# size of the latent space\n","latent_dim = 100\n","\n","if qRestart:\n","        d_model, g_model, gan_model = restart(epochs_done = epochs_done)\n","else:\n","        # create the discriminator\n","        d_model = define_discriminator()\n","        #d_model = load_model(\"generator_model_dis001.h5\")\n","        # create the generator\n","        #g_model = load_model(\"generator_model_001.h5\")\n","        g_model = define_generator(latent_dim)\n","        # create the gan\n","        gan_model = define_gan(g_model, d_model)\n","        #gan_model = load_model(\"generator_model_gan001.h5\")\n","\n","# load image data\n","dataset, cumProbs = load_real_samples()\n","save_real_plots(dataset, nRealPlots=2)\n","#train(g_model, d_model, gan_model,  dataset, latent_dim, epochs_goal=epochs_goal, n_batch=128, epochs_done=epochs_done)\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["**********  ENTERED discriminator  *****************\n",">>embedding>> in_shape[0], in_shape[1], n_nodes:  80 80 6400\n","\n","in_image:  Tensor(\"input_2:0\", shape=(None, 80, 80, 3), dtype=float32)\n","\n","merge.shape:  (None, 80, 80, 4)\n","fe.shape:  (None, 80, 80, 128)\n","fe.shape:  (None, 40, 40, 128)\n","fe.shape:  (None, 20, 20, 128)\n","fe.shape:  (None, 10, 10, 128)\n","fe.shape:  (None, 5, 5, 128)\n","fe flatten shape:  (None, 3200)\n","out_layer.shape:  (None, 1)\n","\n","model:  <tensorflow.python.keras.engine.training.Model object at 0x7fc81b0c6e48>\n","\n","embedding_layer.get_weights(): \n"," [array([[-1.63886771e-02,  3.64713930e-02,  1.88586228e-02,\n","        -2.07912568e-02, -3.40422764e-02,  1.28261745e-05,\n","         4.44148295e-02, -3.61596234e-02],\n","       [-2.89726853e-02,  2.40877010e-02,  2.51197256e-02,\n","        -4.83163372e-02,  2.13210694e-02, -3.42536718e-02,\n","        -4.49862853e-02,  9.10126045e-03],\n","       [-4.67386022e-02,  4.32643406e-02,  3.35728861e-02,\n","         4.08042707e-02,  3.37767340e-02, -4.50802222e-02,\n","        -2.39961389e-02, -1.84829123e-02],\n","       [-4.52143066e-02, -1.24306567e-02, -3.11748143e-02,\n","        -2.79461872e-02,  1.41026825e-03, -7.87893683e-03,\n","        -1.21225230e-02,  8.44944641e-03]], dtype=float32)]\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 1, 8)         32          input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1, 6400)      57600       embedding[0][0]                  \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 80, 80, 3)]  0                                            \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 80, 80, 1)    0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 80, 80, 4)    0           input_2[0][0]                    \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 80, 80, 128)  12928       concatenate[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 80, 80, 128)  0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 80, 80, 128)  0           leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 40, 40, 128)  409728      dropout[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 40, 40, 128)  0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 128)  409728      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 20, 20, 128)  0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 10, 10, 128)  409728      leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 10, 10, 128)  0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 128)    409728      leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 5, 5, 128)    0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 3200)         0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            3201        flatten[0][0]                    \n","==================================================================================================\n","Total params: 1,712,673\n","Trainable params: 1,712,673\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","**********  ENTERED generator  *****************\n","generator...  n_nodes, li.shape:  25 (None, 5, 5, 1)\n","genX.shape:  (None, 5, 5, 128)\n","merge.shape:  (None, 5, 5, 129)\n","gen after CV2DT.shape:  (None, 10, 10, 128)\n","gen.shape:  (None, 10, 10, 128)\n","gen.shape:  (None, 20, 20, 128)\n","gen.shape:  (None, 40, 40, 128)\n","gen.shape:  (None, 80, 80, 128)\n","out_layer.shape:  (None, 80, 80, 3)\n","\n","embedding_layer.get_weights(): \n"," [array([[ 0.01875905,  0.02587242,  0.03995885,  0.00032847,  0.00617566,\n","        -0.04409814, -0.0224099 , -0.03220405],\n","       [ 0.0100438 ,  0.01582737,  0.0374483 , -0.01546516,  0.03715367,\n","        -0.02854936, -0.0054361 , -0.00780519],\n","       [-0.02614075,  0.00959766, -0.02512511,  0.04690843, -0.02090244,\n","        -0.03609411, -0.00965761,  0.02323106],\n","       [-0.03063061,  0.04079742,  0.00577544,  0.00275228, -0.04531846,\n","         0.02654025, -0.00167086,  0.01511863]], dtype=float32)]\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 3200)         323200      input_4[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1, 8)         32          input_3[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 3200)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1, 25)        225         embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 5, 5, 128)    0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 5, 5, 1)      0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 5, 5, 129)    0           reshape_2[0][0]                  \n","                                                                 reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspo (None, 10, 10, 128)  264320      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 10, 10, 128)  0           conv2d_transpose[0][0]           \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 10, 10, 128)  0           leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 20, 20, 128)  262272      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 20, 20, 128)  0           conv2d_transpose_1[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 40, 40, 128)  262272      leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)       (None, 40, 40, 128)  0           conv2d_transpose_2[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 80, 80, 128)  262272      leaky_re_lu_8[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, 80, 80, 128)  0           conv2d_transpose_3[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 80, 80, 3)    9603        leaky_re_lu_9[0][0]              \n","==================================================================================================\n","Total params: 1,384,196\n","Trainable params: 1,384,196\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","**********  ENTERED gan  *****************\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 3200)         323200      input_4[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1, 8)         32          input_3[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 3200)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1, 25)        225         embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 5, 5, 128)    0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 5, 5, 1)      0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 5, 5, 129)    0           reshape_2[0][0]                  \n","                                                                 reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspo (None, 10, 10, 128)  264320      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 10, 10, 128)  0           conv2d_transpose[0][0]           \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 10, 10, 128)  0           leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 20, 20, 128)  262272      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 20, 20, 128)  0           conv2d_transpose_1[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 40, 40, 128)  262272      leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)       (None, 40, 40, 128)  0           conv2d_transpose_2[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 80, 80, 128)  262272      leaky_re_lu_8[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, 80, 80, 128)  0           conv2d_transpose_3[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 80, 80, 3)    9603        leaky_re_lu_9[0][0]              \n","__________________________________________________________________________________________________\n","model (Model)                   (None, 1)            1712673     conv2d_5[0][0]                   \n","                                                                 input_3[0][0]                    \n","==================================================================================================\n","Total params: 3,096,869\n","Trainable params: 1,384,196\n","Non-trainable params: 1,712,673\n","__________________________________________________________________________________________________\n","cols:  Index(['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n","       'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n","       'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n","       'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n","       'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n","       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n","       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n","       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n","       'Wearing_Necklace', 'Wearing_Necktie', 'Young'],\n","      dtype='object')\n","\n","*****  ATTRIBUTES: \n"," 5_o_Clock_Shadow      0.091\n","Arched_Eyebrows       0.377\n","Attractive            1.000\n","Bags_Under_Eyes       0.133\n","Bald                  0.001\n","Bangs                 0.173\n","Big_Lips              0.268\n","Big_Nose              0.120\n","Black_Hair            0.243\n","Blond_Hair            0.203\n","Blurry                0.012\n","Brown_Hair            0.256\n","Bushy_Eyebrows        0.160\n","Chubby                0.004\n","Double_Chin           0.004\n","Eyeglasses            0.011\n","Goatee                0.028\n","Gray_Hair             0.003\n","Heavy_Makeup          0.614\n","High_Cheekbones       0.523\n","Male                  0.227\n","Mouth_Slightly_Open   0.494\n","Mustache              0.014\n","Narrow_Eyes           0.095\n","No_Beard              0.907\n","Oval_Face             0.368\n","Pale_Skin             0.060\n","Pointy_Nose           0.373\n","Receding_Hairline     0.033\n","Rosy_Cheeks           0.103\n","Sideburns             0.034\n","Smiling               0.550\n","Straight_Hair         0.227\n","Wavy_Hair             0.419\n","Wearing_Earrings      0.235\n","Wearing_Hat           0.020\n","Wearing_Lipstick      0.705\n","Wearing_Necklace      0.144\n","Wearing_Necktie       0.033\n","Young                 0.936\n","dtype: float64\n","face_male:  0.22692\n","face_male:  0.22692\n","face_high_cheekbones:  0.52346\n","face_high_cheekbones:  0.52346\n","face_big_lips:  0.26826\n","face_big_lips:  0.26826\n","categ.mean()):  0.0\n","add face_male: categs.mean()):  0.22692\n","add high_cheekbones: categs.mean()):  1.13432\n","add big lips: categs.mean()):  1.45262\n","\n","categs: \n"," [2 0 3 ... 2 2 3]\n","freqCategs:  [(0, 10664), (1, 11346), (2, 22685), (3, 5305)]\n","freqListX:  [10664. 11346. 22685.  5305.]\n","len(categs):  50000\n","cumProbs:  [0.21328 0.22692 0.4537  0.1061 ]\n","cumProbs:  [0.         0.21328001 0.4402     0.89390001 1.00000001]\n","real_plots:  0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MDhyMdcOCm0z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}