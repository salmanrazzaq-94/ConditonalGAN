{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWTZVK0_Dq4a"
   },
   "source": [
    "# This note for FID Score Calculation of our CGAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQ184D6NkLQQ"
   },
   "source": [
    "Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RwYz6or5kLQS",
    "outputId": "79572d64-8040-4530-c0eb-438fd5adfb52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy.random import shuffle\n",
    "from scipy.linalg import sqrtm\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.datasets.mnist import load_data\n",
    "from skimage.transform import resize\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from numpy.random import randint\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "EjWxc5O0N9RS",
    "outputId": "90e5de7d-8704-4933-bfa3-7d5bb8644a8d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "oFY3Fde5N9cc",
    "outputId": "ec3a38ff-5337-482b-d129-39935c948bde"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/My Drive/deeplearning/\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXRKp7q5kLQm"
   },
   "source": [
    "This model can be used to predict the feature vector for one or more images. Our images are likely to not have the required shape. We will use the scikit-image library to resize the NumPy array of pixel values to the required size. The scale images() function below implements this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPPe7swfE1gQ"
   },
   "outputs": [],
   "source": [
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIFhKcLRkLQt"
   },
   "source": [
    "Once resized, the image pixel values will also need to be scaled to meet the expectations for inputs to the inception model. This can be achieved by calling the preprocess input() function. We can update our calculate fid() function defined in the theory to take the loaded inception model and two NumPy arrays of image data as arguments, instead of activations. The function will then calculate the activations before calculating the FID score as before. The updated version of the calculate_fid() function is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ro-WFv2gE5c3"
   },
   "outputs": [],
   "source": [
    "# calculate frechet inception distance\n",
    "def calculate_fid(model, images1, images2):\n",
    "    # calculate activations\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aThJY9NhNygu",
    "outputId": "7a9bdf64-52ac-4a91-ae30-8593fa569479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "real_data_file = \"img_align_celeba_attractive_face.npz\"\n",
    "images1 = numpy.load(real_data_file)[\"arr_0\"]\n",
    "images1 = images1[:10000]\n",
    "#images1 = (images1 - 127.5) / 127.5\n",
    "#images1 = (images1 + 1) / 2.0\n",
    "print(images1.shape)\n",
    "#print(images1[0,:,:])\n",
    "#print('Loaded', images1.shape, images2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "FsblSL5kORLu",
    "outputId": "8210bee7-778a-434d-ea32-8d39e99787db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n",
      "[0 0 0 ... 2 1 3]\n",
      "(10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"results/models/generator_model_200.h5\")\n",
    "CGAN_data_file = \"results/latent_points/latent_points_10000.npz\"\n",
    "latent_points = numpy.load(CGAN_data_file)[\"arr_0\"]\n",
    "print(latent_points.shape)\n",
    "# generate images\n",
    "labels = randint(0, 4, 10000)\n",
    "print(labels)\n",
    "images2 = model.predict([latent_points, labels])\n",
    "# scale from [-1,1] to [0,1]\n",
    "#images2 = (images2 + 1) / 2.0\n",
    "# scale from [-1,1] to [0,255]\n",
    "images2 = (images2 * 127.5) + 127.5\n",
    "print(images2.shape)\n",
    "#print(images2[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U6cA4fhTkLQ8"
   },
   "source": [
    "Then, we can load the Inception v3 model in Keras directly. This will prepare a version of the inception model for classifying images as one of 1,000 known classes. We can remove the output (the top) of the model via the include top=False argument. Painfully, this also removes the global average pooling layer that we require, but we can add it back via specifying the pooling=‘avg’ argument. When the output layer of the model is removed, we must specify the shape of the input images, which is 299 × 299 × 3 pixels, e.g. the input shape=(299,299,3) argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "HFE_iXlZE7k3",
    "outputId": "ef70aa96-2bfe-42d4-e16a-94d36c24e087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "Loaded (10000, 64, 64, 3) (10000, 64, 64, 3)\n",
      "Scaled (10000, 299, 299, 3) (10000, 299, 299, 3)\n",
      "Preprocessed (10000, 299, 299, 3) (10000, 299, 299, 3)\n",
      "FID: 21.361\n"
     ]
    }
   ],
   "source": [
    "# prepare the inception v3 model\n",
    "model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "print('Loaded', images1.shape, images2.shape)\n",
    "# convert integer to floating point values\n",
    "images1 = images1.astype('float32')\n",
    "images2 = images2.astype('float32')\n",
    "# resize images\n",
    "images1 = scale_images(images1, (299,299,3))\n",
    "images2 = scale_images(images2, (299,299,3))\n",
    "print('Scaled', images1.shape, images2.shape)\n",
    "# pre-process images\n",
    "images1 = preprocess_input(images1)\n",
    "images2 = preprocess_input(images2)\n",
    "print('Preprocessed', images1.shape, images2.shape)\n",
    "# calculate fid\n",
    "fid = calculate_fid(model, images1, images2)\n",
    "print('FID: %.3f' % fid)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "FID_Score_CGAN_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
