{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wDxf48r1_YlQ",
    "outputId": "c5795672-d45c-4459-f574-0675e97adcc4"
   },
   "source": [
    "# This notenook for proposing metrics for accessing the conditions of our generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy import savez_compressed\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "rXk6drMB_qE_",
    "outputId": "3f565dc9-c374-412e-c954-e7f1a197cc59"
   },
   "outputs": [],
   "source": [
    "#Mount the Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir(\"/content/drive/My Drive/deeplearning/\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLJLsTaM4FhB"
   },
   "outputs": [],
   "source": [
    "#    INDICATE IF STARTING FRESH OR CONTINUING FROM PREVIOUS RUN\n",
    "qRestart = True\n",
    "if qRestart:\n",
    "    epochs_done = 15\n",
    "    epochs_goal = 100\n",
    "else:\n",
    "    epochs_done = 0\n",
    "    epochs_goal = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ysEFOrdbJzA"
   },
   "source": [
    "We will define a classifier using our already made discriminator model. The difference is that now we will only use a sequential model and use a crossentropy loss function with softmax activation as we want our model to classify images belonging to one of the four categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gbx_C6oPYoXx"
   },
   "outputs": [],
   "source": [
    "#define the standalone discriminator model\n",
    "def define_classifier(in_shape=(64,64,3)):\n",
    "  model = Sequential()\n",
    "  # normal\n",
    "  model.add(Conv2D(128, (5,5), padding='same', input_shape=in_shape))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  # downsample to 32x32\n",
    "  model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  # downsample to 16x16\n",
    "  model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  # downsample to 8x8\n",
    "  model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  # downsample to 4x4\n",
    "  model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  # classifier\n",
    "  model.add(Flatten())\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(4, activation='softmax'))\n",
    "  # compile model\n",
    "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "  model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRqEapZVbfn_"
   },
   "source": [
    "We will load the real samples from our data for training purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "900q4Rjx-j-O"
   },
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_real_samples():\n",
    "  #Prepare the training Dataset\n",
    "  real_data_file = \"img_align_celeba_attractive_face.npz\"\n",
    "  # load the face dataset\n",
    "  train_images = np.load(real_data_file)[\"arr_0\"]\n",
    "  # convert from unsigned ints to floats\n",
    "  train_images = train_images.astype('float32')\n",
    "  # scale from [0,255] to [-1,1]\n",
    "  train_images = (train_images - 127.5) / 127.5\n",
    "  print(train_images.shape)\n",
    "  return train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qs3X7va_bkrX"
   },
   "source": [
    "Generate real samples for each batch of epoch of training. We will convert our categories to one hot encoding so that they can be use as desired output of our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9M_WrkX-pez"
   },
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "  # choose random instances\n",
    "  ix = randint(0, dataset.shape[0], n_samples)\n",
    "  # retrieve selected images\n",
    "  train_images = dataset[ix]\n",
    "  # generate real class labels (1)\n",
    "  df = pd.read_csv('results/assigned_categories.csv')\n",
    "  labels = df[\"Category\"].values\n",
    "  train_labels = labels[ix]\n",
    "  # print(ix)\n",
    "  # print(train_labels)\n",
    "  # convert integers to dummy variables (i.e. one hot encoded)\n",
    "  encoded_train_labels = np_utils.to_categorical(train_labels, num_classes=4)\n",
    "  #print(encoded_train_labels.shape)\n",
    "  return train_images, encoded_train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59MZOQh0byAf"
   },
   "source": [
    "We will generate 10000 samples of our GAN Model to verify the accuracy of labelling of our generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sjv-w7vdChZD"
   },
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_generated_samples():\n",
    "  model_generator = load_model(\"results/models/generator_model_200.h5\")\n",
    "  CGAN_data_file = \"results/latent_points/latent_points_10000.npz\"\n",
    "  latent_points = np.load(CGAN_data_file)[\"arr_0\"]\n",
    "  print(latent_points.shape)\n",
    "  # generate images\n",
    "  test_labels = randint(0, 4, 10000)\n",
    "  print(test_labels)\n",
    "  test_images = model_generator.predict([latent_points, test_labels])\n",
    "  encoded_train_labels = np_utils.to_categorical(test_labels, num_classes=4)\n",
    "  print(encoded_train_labels.shape)\n",
    "  return test_images, encoded_train_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8vOmjxw3YDx"
   },
   "outputs": [],
   "source": [
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, c_model, dataset, n_samples=100):\n",
    "  # prepare real samples\n",
    "  X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "  # evaluate discriminator on real examples\n",
    "  _ , acc_real = c_model.evaluate(X_real, y_real, verbose=0)\n",
    "  # summarize discriminator performance\n",
    "  print('>Accuracy real: %.0f%%' % (acc_real*100))\n",
    "  # save the generator model tile file\n",
    "  filename = 'results/classifier_models/generator_model_classifier_%03d.h5' % (epoch+1)\n",
    "  c_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xF5Wclr3YGo"
   },
   "outputs": [],
   "source": [
    "def restart(epochs_done):\n",
    "    # gen_weights = array(model.get_weights())\n",
    "    print(\"****  PULLING IN EPOCH: \", epochs_done)\n",
    "    filename = 'results/classifier_models/generator_model_classifier_%03d.h5' % (epochs_done)\n",
    "    c_model = load_model(filename, compile=True)\n",
    "    c_model.trainable = True\n",
    "    for layer in c_model.layers:\n",
    "        layer.trainable = True\n",
    "    c_model.summary()\n",
    "    return c_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfSciKOT3YJr"
   },
   "outputs": [],
   "source": [
    "#train the classifier\n",
    "def train(c_model, dataset, epochs_done, epochs_goal, n_batch=128):\n",
    "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "  now = time.time()\n",
    "  # manually enumerate epochs\n",
    "  for i in range(epochs_done, epochs_goal):\n",
    "  # enumerate batches over the training set\n",
    "    for j in range(bat_per_epo):\n",
    "      # get randomly selected 'real'samples\n",
    "      X_real, y_real = generate_real_samples(dataset, n_batch) \n",
    "      # update discriminator model weights\n",
    "      c_loss1, accuracy_t = c_model.train_on_batch(X_real, y_real)\n",
    "      # summarize loss on this batch\n",
    "      if (j+1) % 50==0:\n",
    "        diff = int(time.time()-now)\n",
    "        print('>Epoch: %d, Batch/Epoch:%d/%d, Model_loss: %.3f, Seconds: %d, Accuracy: %.0f%%' %(i+1, j+1, bat_per_epo, c_loss1, diff, (accuracy_t*100)))\n",
    "  # evaluate the model performance, sometimes\n",
    "    if (i+1) % 5 == 0:\n",
    "      summarize_performance(i, c_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MKA78jte3YMX",
    "outputId": "779c40dc-f263-4fad-be08-ab7e12ec846f"
   },
   "outputs": [],
   "source": [
    "if qRestart:\n",
    "        c_model = restart(epochs_done = epochs_done)\n",
    "else:\n",
    "        # create the discriminator\n",
    "        c_model = define_classifier()\n",
    "\n",
    "\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "train(c_model, dataset, epochs_done=epochs_done, epochs_goal=epochs_goal, n_batch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OV-W3Ew3YRZ"
   },
   "outputs": [],
   "source": [
    "#Evaluation metric for generated images:\n",
    "classifier_model = load_model(results/classifier_models/generator_model_classifier_100.h5)\n",
    "#evaluate discriminator on generated examples\n",
    "generated_images, generated_labels = load_generated_samples()\n",
    "#summarize discriminator performance\n",
    "loss, acc_gen = classifier_model.evaluate(generated_images, generated_labels, verbose=0)\n",
    "#summarize discriminator performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFqdfR27OaMV"
   },
   "outputs": [],
   "source": [
    "#summarize discriminator performance\n",
    "print('>Accuracy Generated: %.0f%%' % (acc_gen*100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CGANClassifierFinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
